{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pmlb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmlb import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                N0           N1           N2           N3           N4  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
      "mean      0.020625     0.261250     0.728750     0.889375     0.354375   \n",
      "std       0.142170     0.475015     0.673949     0.702635     0.523416   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     1.000000     1.000000     0.000000   \n",
      "75%       0.000000     0.000000     1.000000     1.000000     1.000000   \n",
      "max       1.000000     2.000000     2.000000     2.000000     2.000000   \n",
      "\n",
      "                N5           N6           N7           N8           N9  ...  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000  ...   \n",
      "mean      0.791250     0.502500     0.728750     0.346875     0.761875  ...   \n",
      "std       0.695864     0.615614     0.684994     0.540125     0.694062  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "50%       1.000000     0.000000     1.000000     0.000000     1.000000  ...   \n",
      "75%       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
      "max       2.000000     2.000000     2.000000     2.000000     2.000000  ...   \n",
      "\n",
      "               N11          N12          N13          N14          N15  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
      "mean      0.860000     0.478125     0.076250     0.178125     0.666250   \n",
      "std       0.712894     0.606012     0.270151     0.398743     0.657747   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       1.000000     0.000000     0.000000     0.000000     1.000000   \n",
      "75%       1.000000     1.000000     0.000000     0.000000     1.000000   \n",
      "max       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
      "\n",
      "               N16          N17           P1           P2       target  \n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000  \n",
      "mean      0.425625     0.778750     0.406250     0.404375     0.500000  \n",
      "std       0.576347     0.703639     0.578939     0.562186     0.500156  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       0.000000     1.000000     0.000000     0.000000     0.500000  \n",
      "75%       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "max       2.000000     2.000000     2.000000     2.000000     1.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# dataset for this demo\n",
    "#https://github.com/EpistasisLab/penn-ml-benchmarks/tree/master/datasets/classification/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1\n",
    "gametes = fetch_data('GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1')\n",
    "print(gametes.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N0</th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>...</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>N15</th>\n",
       "      <th>N16</th>\n",
       "      <th>N17</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   N0  N1  N2  N3  N4  N5  N6  N7  N8  N9  ...  N11  N12  N13  N14  N15  N16  \\\n",
       "0   0   0   2   1   1   0   0   2   0   1  ...    2    1    0    0    0    0   \n",
       "1   0   0   1   0   0   1   1   0   0   1  ...    0    1    0    0    0    0   \n",
       "2   0   0   0   1   0   2   0   0   0   0  ...    1    1    0    0    2    2   \n",
       "3   0   1   0   2   0   1   0   2   0   0  ...    1    1    0    1    1    0   \n",
       "4   0   0   1   1   0   0   0   1   1   0  ...    1    0    0    1    0    0   \n",
       "\n",
       "   N17  P1  P2  target  \n",
       "0    0   0   1       1  \n",
       "1    0   0   0       1  \n",
       "2    0   0   0       1  \n",
       "3    1   1   0       1  \n",
       "4    1   1   0       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gametes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=gametes.drop('target',axis=1)\n",
    "\n",
    "# features for A\n",
    "A_feat_list = [\n",
    "                'N10',\n",
    "                'N11',\n",
    "                'N12'\n",
    "                ]\n",
    "\n",
    "# features for C\n",
    "C_feat_list = [\n",
    "                'N13',\n",
    "                'N14',\n",
    "                'N15'\n",
    "                ]\n",
    "# y\n",
    "\n",
    "y = gametes['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary',\n",
       "  'ternary']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test metaestimator alone\n",
    "\n",
    "# without subset option\n",
    "from tpot.builtins import MetaClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "metaest = MetaClassifier(estimator=GradientBoostingRegressor(random_state=42), A=A_feat_list, C=C_feat_list)\n",
    "metaest.fit(X_train, y_train)\n",
    "metaest.values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N0</th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>N15</th>\n",
       "      <th>N16</th>\n",
       "      <th>N17</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      N0  N1  N2  N3  N4  N5  N6  N7  N8  N9  N10  N11  N12  N13  N14  N15  \\\n",
       "820    0   0   0   2   1   1   0   1   1   0    0    1    1    1    0    0   \n",
       "567    0   0   0   0   0   0   0   0   0   0    0    2    2    0    1    0   \n",
       "355    0   1   0   1   1   1   1   1   0   1    0    1    2    0    0    0   \n",
       "1545   0   0   0   2   1   0   0   1   1   2    0    0    0    0    0    1   \n",
       "209    0   0   1   2   1   2   2   0   0   0    0    1    1    1    0    0   \n",
       "\n",
       "      N16  N17  P1  P2  \n",
       "820     1    1   1   1  \n",
       "567     0    2   0   1  \n",
       "355     1    0   0   0  \n",
       "1545    2    1   1   1  \n",
       "209     0    2   0   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = metaest.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7294635022771905\n"
     ]
    }
   ],
   "source": [
    "from tpot.metrics import balanced_accuracy\n",
    "b_acc = balanced_accuracy(y_true=y_train, y_pred=y_pred)\n",
    "print(b_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5492424242424242\n"
     ]
    }
   ],
   "source": [
    "print(metaest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ternary', 'ternary', 'ternary']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with subset option\n",
    "# only one subset\n",
    "metaest = MetaClassifier(estimator=GradientBoostingRegressor(random_state=42), \n",
    "                            A=A_feat_list, \n",
    "                            C=C_feat_list,\n",
    "                            subset=['N1', 'N2', 'N3']) #only convert N1, N2 and N3\n",
    "metaest.fit(X_train, y_train)\n",
    "metaest.values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7294635022771905\n",
      "0.7443181818181818\n"
     ]
    }
   ],
   "source": [
    "b_acc = balanced_accuracy(y_true=y_train, y_pred=y_pred)\n",
    "print(b_acc)\n",
    "print(metaest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ternary'], ['ternary', 'ternary'], ['ternary', 'ternary']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with subset option\n",
    "# a list of subsets\n",
    "# 1st list should be C\n",
    "# 2nd list should be subset of features for transfromation/adjust\n",
    "subset_tuple = ((['N13', 'N14', 'N15'], ['N1']), # confounding variable N13-15 should adjust N1\n",
    "               (['N13'], ['N2', 'N3']), # confounding variable N13 should adjust N2-3\n",
    "               (['N14', 'N15'], ['N4', 'N5'])) # confounding variable N14-15 should adjust N4-5\n",
    "metaest = MetaClassifier(estimator=GradientBoostingRegressor(random_state=42), \n",
    "                            A=A_feat_list, \n",
    "                            C=C_feat_list,\n",
    "                            subset=subset_tuple) #only convert N1, N2 and N3\n",
    "metaest.fit(X_train, y_train)\n",
    "metaest.values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7294635022771905\n",
      "0.7178030303030303\n"
     ]
    }
   ],
   "source": [
    "b_acc = balanced_accuracy(y_true=y_train, y_pred=y_pred)\n",
    "print(b_acc)\n",
    "print(metaest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metaestimator is passed when using it as a stand-alone estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score is matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=150.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=3 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=4 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=5 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=6 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=7 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=8 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=9 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _mate_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=1 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=2 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=3 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=4 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=5 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=6 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _mate_operator: num_test=7 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=8 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=9 'N4'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=3 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=4 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=5 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=6 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=7 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=8 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=9 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=3 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=4 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=5 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=6 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=7 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=8 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=9 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 not enough values to unpack (expected 2, got 1).\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-2\t0.5135687046782771\tMetaClassifier(FeatureSetSelector(input_matrix, FeatureSetSelector__res_cols=['N10', 'N11', 'N12', 'N13', 'N14', 'N15'], FeatureSetSelector__sel_subset=1, FeatureSetSelector__subset_list=./subset_test.csv), MetaClassifier__A=['N10', 'N11', 'N12'], MetaClassifier__C=['N13', 'N14', 'N15'], MetaClassifier__GradientBoostingRegressor__alpha=0.95, MetaClassifier__GradientBoostingRegressor__learning_rate=1.0, MetaClassifier__GradientBoostingRegressor__loss=ls, MetaClassifier__GradientBoostingRegressor__max_depth=6, MetaClassifier__GradientBoostingRegressor__max_features=0.45, MetaClassifier__GradientBoostingRegressor__min_samples_leaf=16, MetaClassifier__GradientBoostingRegressor__min_samples_split=5, MetaClassifier__GradientBoostingRegressor__n_estimators=100, MetaClassifier__GradientBoostingRegressor__subsample=0.3, MetaClassifier__subset=(['N14', 'N15'], ['N4', 'N5']))\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-2\t0.5135687046782771\tMetaClassifier(FeatureSetSelector(input_matrix, FeatureSetSelector__res_cols=['N10', 'N11', 'N12', 'N13', 'N14', 'N15'], FeatureSetSelector__sel_subset=1, FeatureSetSelector__subset_list=./subset_test.csv), MetaClassifier__A=['N10', 'N11', 'N12'], MetaClassifier__C=['N13', 'N14', 'N15'], MetaClassifier__GradientBoostingRegressor__alpha=0.95, MetaClassifier__GradientBoostingRegressor__learning_rate=1.0, MetaClassifier__GradientBoostingRegressor__loss=ls, MetaClassifier__GradientBoostingRegressor__max_depth=6, MetaClassifier__GradientBoostingRegressor__max_features=0.45, MetaClassifier__GradientBoostingRegressor__min_samples_leaf=16, MetaClassifier__GradientBoostingRegressor__min_samples_split=5, MetaClassifier__GradientBoostingRegressor__n_estimators=100, MetaClassifier__GradientBoostingRegressor__subsample=0.3, MetaClassifier__subset=(['N14', 'N15'], ['N4', 'N5']))\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 too many values to unpack (expected 2).\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-2\t0.5184314946492548\tMetaClassifier(FeatureSetSelector(input_matrix, FeatureSetSelector__res_cols=['N10', 'N11', 'N12', 'N13', 'N14', 'N15'], FeatureSetSelector__sel_subset=1, FeatureSetSelector__subset_list=./subset_test.csv), MetaClassifier__A=['N10', 'N11', 'N12'], MetaClassifier__C=['N13', 'N14', 'N15'], MetaClassifier__GradientBoostingRegressor__alpha=0.95, MetaClassifier__GradientBoostingRegressor__learning_rate=1.0, MetaClassifier__GradientBoostingRegressor__loss=lad, MetaClassifier__GradientBoostingRegressor__max_depth=3, MetaClassifier__GradientBoostingRegressor__max_features=0.6500000000000001, MetaClassifier__GradientBoostingRegressor__min_samples_leaf=14, MetaClassifier__GradientBoostingRegressor__min_samples_split=4, MetaClassifier__GradientBoostingRegressor__n_estimators=100, MetaClassifier__GradientBoostingRegressor__subsample=0.4, MetaClassifier__subset=(['N14', 'N15'], ['N4', 'N5']))\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 4 - Current Pareto front scores:\n",
      "-2\t0.5184314946492548\tMetaClassifier(FeatureSetSelector(input_matrix, FeatureSetSelector__res_cols=['N10', 'N11', 'N12', 'N13', 'N14', 'N15'], FeatureSetSelector__sel_subset=1, FeatureSetSelector__subset_list=./subset_test.csv), MetaClassifier__A=['N10', 'N11', 'N12'], MetaClassifier__C=['N13', 'N14', 'N15'], MetaClassifier__GradientBoostingRegressor__alpha=0.95, MetaClassifier__GradientBoostingRegressor__learning_rate=1.0, MetaClassifier__GradientBoostingRegressor__loss=lad, MetaClassifier__GradientBoostingRegressor__max_depth=3, MetaClassifier__GradientBoostingRegressor__max_features=0.6500000000000001, MetaClassifier__GradientBoostingRegressor__min_samples_leaf=14, MetaClassifier__GradientBoostingRegressor__min_samples_split=4, MetaClassifier__GradientBoostingRegressor__n_estimators=100, MetaClassifier__GradientBoostingRegressor__subsample=0.4, MetaClassifier__subset=(['N14', 'N15'], ['N4', 'N5']))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 'N4'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 too many values to unpack (expected 2).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 not enough values to unpack (expected 2, got 1).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 too many values to unpack (expected 2).\n",
      "Generation 5 - Current Pareto front scores:\n",
      "-2\t0.5184314946492548\tMetaClassifier(FeatureSetSelector(input_matrix, FeatureSetSelector__res_cols=['N10', 'N11', 'N12', 'N13', 'N14', 'N15'], FeatureSetSelector__sel_subset=1, FeatureSetSelector__subset_list=./subset_test.csv), MetaClassifier__A=['N10', 'N11', 'N12'], MetaClassifier__C=['N13', 'N14', 'N15'], MetaClassifier__GradientBoostingRegressor__alpha=0.95, MetaClassifier__GradientBoostingRegressor__learning_rate=1.0, MetaClassifier__GradientBoostingRegressor__loss=lad, MetaClassifier__GradientBoostingRegressor__max_depth=3, MetaClassifier__GradientBoostingRegressor__max_features=0.6500000000000001, MetaClassifier__GradientBoostingRegressor__min_samples_leaf=14, MetaClassifier__GradientBoostingRegressor__min_samples_split=4, MetaClassifier__GradientBoostingRegressor__n_estimators=100, MetaClassifier__GradientBoostingRegressor__subsample=0.4, MetaClassifier__subset=(['N14', 'N15'], ['N4', 'N5']))\n",
      "\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'tpot.builtins.FeatureSetSelector': {'res_cols': [['N10',\n",
       "                                                                               'N11',\n",
       "                                                                               'N12',\n",
       "                                                                               'N13',\n",
       "                                                                               'N14',\n",
       "                                                                               'N15']],\n",
       "                                                                 'sel_subset': [0,\n",
       "                                                                                1],\n",
       "                                                                 'subset_list': ['./subset_test.csv']},\n",
       "                            'tpot.builtins.MetaClassifier': {'A': [['N10',\n",
       "                                                                    'N11',\n",
       "                                                                    'N12']],\n",
       "                                                             'C': [['N13',\n",
       "                                                                    'N14',\n",
       "                                                                    'N15']],\n",
       "                                                             'estimator': {'sklearn.ensemble.GradientBoostingRegressor': {'alpha': [0.75,\n",
       "                                                                                                                                    0.8,\n",
       "                                                                                                                                    0.85,\n",
       "                                                                                                                                    0.9,\n",
       "                                                                                                                                    0.95,\n",
       "                                                                                                                                    0.99...\n",
       "               crossover_rate=0.1, cv=5, disable_update_check=False,\n",
       "               early_stop=None, generations=5, max_eval_time_mins=5,\n",
       "               max_time_mins=None, memory=None, mutation_rate=0.9, n_jobs=1,\n",
       "               offspring_size=None, periodic_checkpoint_folder=None,\n",
       "               population_size=25, random_state=42, scoring='balanced_accuracy',\n",
       "               subsample=1.0, template='FeatureSetSelector-Classifier',\n",
       "               use_dask=False, verbosity=3, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metaestimator with TPOT with config\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "subset_tuple = ((['N13', 'N14', 'N15'], ['N1']), # confounding variable N13-15 should adjust N1\n",
    "               (['N13'], ['N2', 'N3']), # confounding variable N13 should adjust N2-3\n",
    "               (['N14', 'N15'], ['N4', 'N5'])) # confounding variable N14-15 should adjust N4-5\n",
    "\n",
    "\n",
    "tpot_config = {\n",
    "    'tpot.builtins.FeatureSetSelector': {\n",
    "        'subset_list': ['./subset_test.csv'],\n",
    "        'sel_subset': [0, 1],\n",
    "        'res_cols': [['N10', 'N11', 'N12', 'N13', 'N14', 'N15']]\n",
    "    },\n",
    "   'tpot.builtins.MetaClassifier': {\n",
    "        \n",
    "        'estimator': {\n",
    "           'sklearn.ensemble.GradientBoostingRegressor': {\n",
    "                'n_estimators': [100],\n",
    "                'loss': [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "                'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "                'max_depth': range(1, 11),\n",
    "                'min_samples_split': range(2, 21),\n",
    "                'min_samples_leaf': range(1, 21),\n",
    "                'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "                'alpha': [0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "            },\n",
    "\n",
    "        },\n",
    "       'A': [A_feat_list],\n",
    "       'C': [C_feat_list],\n",
    "       'subset': subset_tuple\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=25, \n",
    "                        verbosity=3, cv=5,\n",
    "                      config_dict=tpot_config,\n",
    "                      template=\"FeatureSetSelector-Classifier\",\n",
    "                      scoring=\"balanced_accuracy\",random_state=42)\n",
    "tpot.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MetaClassifier(FeatureSetSelector(input_matrix, FeatureSetSelector__res_cols=['N10', 'N11', 'N12', 'N13', 'N14', 'N15'], FeatureSetSelector__sel_subset=1, FeatureSetSelector__subset_list=./subset_test.csv), MetaClassifier__A=['N10', 'N11', 'N12'], MetaClassifier__C=['N13', 'N14', 'N15'], MetaClassifier__GradientBoostingRegressor__alpha=0.75, MetaClassifier__GradientBoostingRegressor__learning_rate=0.5, MetaClassifier__GradientBoostingRegressor__loss=quantile, MetaClassifier__GradientBoostingRegressor__max_depth=8, MetaClassifier__GradientBoostingRegressor__max_features=0.55, MetaClassifier__GradientBoostingRegressor__min_samples_leaf=19, MetaClassifier__GradientBoostingRegressor__min_samples_split=18, MetaClassifier__GradientBoostingRegressor__n_estimators=100, MetaClassifier__GradientBoostingRegressor__subsample=0.4, MetaClassifier__subset=(['N14', 'N15'], ['N4', 'N5']))\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tpot.evaluated_individuals_.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5246422208172883\n"
     ]
    }
   ],
   "source": [
    "print(tpot.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
